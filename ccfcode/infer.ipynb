{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "\n",
    "from data_deal import _tokenize_chinese_text, Tokenizer4Bert\n",
    "from models import BERT_SPC\n",
    "from pytorch_pretrained_bert import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inferer:\n",
    "    \"\"\"A simple inference example\"\"\"\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt\n",
    "        print(\"loading {0} tokenizer...\".format(opt.dataset))\n",
    "        self.bert_tokenizer = Tokenizer4Bert('bert-base-chinese')\n",
    "\n",
    "        self.model_list = []\n",
    "        for i, model_name in enumerate(opt.model_name_list):\n",
    "            print('loading model {0}... '.format(model_name))\n",
    "            bert = BertModel.from_pretrained('bert-base-chinese')\n",
    "            model = nn.DataParallel(opt.model_class_list[i](bert, opt).to(opt.device))\n",
    "            model.load_state_dict(torch.load(opt.state_dict_path_list[i]))\n",
    "            # switch model to evaluation mode\n",
    "            model.eval()\n",
    "            self.model_list.append(model)\n",
    "        \n",
    "        torch.autograd.set_grad_enabled(False)\n",
    "\n",
    "    def evaluate(self, fname):\n",
    "        fin = open(fname, 'r', encoding='utf-8-sig', newline='\\n', errors='ignore')\n",
    "        fin_csv = csv.reader(fin)\n",
    "        fout = open('../ccfresult/submission.csv', 'w', encoding='utf-8-sig', newline='')\n",
    "        fout_csv = csv.writer(fout)\n",
    "        header = ['id','negative','key_entity']\n",
    "        fout_csv.writerow(header)\n",
    "        for i, row in enumerate(fin_csv):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            else:\n",
    "                key_entities = []\n",
    "                uid = row[0]\n",
    "                text_raw = row[1]\n",
    "                entities = row[2].split(';')\n",
    "                for entity in entities:\n",
    "                    if entity == '' or entity == ' ':\n",
    "                        break\n",
    "                    aspect = entity\n",
    "                    text_left, _, text_right = [s for s in text_raw.partition(entity)]\n",
    "                    text_left = _tokenize_chinese_text(text_left)\n",
    "                    text_right = _tokenize_chinese_text(text_right)\n",
    "                    aspect = _tokenize_chinese_text(aspect)\n",
    "                    _text_indices = self.bert_tokenizer.text_to_sequence(text_left+' '+aspect+' '+text_right)\n",
    "                    _aspect_indices = self.bert_tokenizer.text_to_sequence(aspect)\n",
    "                    bert_text_indices = [(self.bert_tokenizer.text_to_sequence('[CLS]') + _text_indices +\\\n",
    "                         self.bert_tokenizer.text_to_sequence('[SEP]') + _aspect_indices + self.bert_tokenizer.text_to_sequence('[SEP]'))[:512]]\n",
    "                    bert_segment_indices = [([0] * (len(_text_indices) + 2) + [1] * (len(_aspect_indices) + 1))[:512]]\n",
    "                    data = {\n",
    "                        'bert_text_indices': torch.tensor(bert_text_indices),\n",
    "                        'bert_segment_indices': torch.tensor(bert_segment_indices),\n",
    "                    }\n",
    "                    preds = []\n",
    "                    for i, inputs_cols in enumerate(self.opt.inputs_cols_list):\n",
    "                        t_inputs = [data[col].to(self.opt.device) for col in inputs_cols]\n",
    "                        with torch.no_grad():\n",
    "                            t_outputs = self.model_list[i](t_inputs)\n",
    "                        t_preds = t_outputs.argmax(dim=1).cpu().numpy()[0]\n",
    "                        preds.append(t_preds)\n",
    "                    preds = max(preds, key=preds.count)\n",
    "                    if preds == 1:\n",
    "                        key_entities.append(entity)\n",
    "                if len(key_entities) == 0:\n",
    "                    fout_csv.writerow([uid, '0', ''])\n",
    "                else:\n",
    "                    fout_csv.writerow([uid, '1', ';'.join(key_entities)])\n",
    "        fin.close()\n",
    "        fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading finance tokenizer...\n",
      "loading model bert... \n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    model_classes = {\n",
    "        'bert': BERT_SPC\n",
    "    }\n",
    "    dataset = 'finance'\n",
    "    # set your trained models here\n",
    "    model_state_dict_paths = {\n",
    "        'bert': 'state_dict/bert_'+dataset+'.pkl',\n",
    "    }\n",
    "    input_colses = {\n",
    "        'bert': ['bert_text_indices', 'bert_segment_indices'],\n",
    "    }\n",
    "    class Option(object): pass\n",
    "    opt = Option()\n",
    "    opt.model_name_list = ['bert']\n",
    "    opt.model_class_list = [model_classes[model_name] for model_name in opt.model_name_list]\n",
    "    opt.inputs_cols_list = [input_colses[model_name] for model_name in opt.model_name_list]\n",
    "    opt.dataset = dataset\n",
    "    opt.state_dict_path_list = [model_state_dict_paths[model_name] for model_name in opt.model_name_list]\n",
    "    opt.embed_dim = 300\n",
    "    opt.hidden_dim = 300\n",
    "    opt.polarities_dim = 3\n",
    "    opt.dropout = 0.3\n",
    "    opt.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    inf = Inferer(opt)\n",
    "    inf.evaluate('../ccfdata/Clean_Test_Data.csv')\n",
    "    print(\"ok\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
